## Principle Component Analysis

PCA, or Principal Component Analysis, is a technique used in unsupervised learning to reduce the dimensionality of a dataset while retaining as much of the original information as possible. The goal of PCA is to identify the most important features, or principal components, that explain the variability in the data.

PCA works by transforming the original high-dimensional data into a new set of orthogonal variables, called principal components, that capture the maximum amount of variation in the data. The first principal component captures the most variation, followed by the second, and so on. The number of principal components is typically much smaller than the original number of features, which reduces the dimensionality of the data.

PCA is commonly used in unsupervised learning for exploratory data analysis, data visualization, and feature extraction. By reducing the dimensionality of the data, PCA makes it easier to visualize and understand the relationships between different variables in the dataset. Additionally, PCA can be used to extract important features that can be used as input to other machine learning algorithms, such as clustering or classification.

Overall, PCA is a powerful tool in unsupervised learning that can help improve the efficiency and accuracy of data analysis by reducing the dimensionality of the data while retaining as much information as possible.

Within the notebook you may find an explanation of how the model works as well as an application to the cbb dataset.
